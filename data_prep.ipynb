{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompleteDataSet_validation_tuples.npy\n",
      "CompleteDataSet_training_tuples.npy\n",
      "CompleteDataSet_tuples.npy\n",
      "CompleteDataSet_testing_tuples.npy\n",
      "CompleteImages\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get list of entries in the current directory\n",
    "entries = os.listdir()\n",
    "\n",
    "# Or specify a path\n",
    "entries = os.listdir('./handwritten-digits-and-operators')\n",
    "\n",
    "# Print each entry\n",
    "for entry in entries:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to debug function:\n",
    "def load_images(path):\n",
    "    train_data = []\n",
    "    for file in listdir(path):\n",
    "        # Open the image\n",
    "        img = Image.open(os.path.join(path, file))\n",
    "        # Convert to grayscale\n",
    "        img = img.convert(\"L\")\n",
    "        img = img.resize((64, 64))\n",
    "        img_array = np.array(img)\n",
    "        img_array = 255 - img_array\n",
    "        img_array = img_array.reshape((4096, 1))\n",
    "        \n",
    "        train_data.append(img_array)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\n",
    "    (\"0\", \"0\"),\n",
    "    (\"1\", \"1\"),\n",
    "    (\"2\", \"2\"),\n",
    "    (\"3\", \"3\"),\n",
    "    (\"4\", \"4\"),\n",
    "    (\"5\", \"5\"),\n",
    "    (\"6\", \"6\"),\n",
    "    (\"7\", \"7\"),\n",
    "    (\"8\", \"8\"),\n",
    "    (\"9\", \"9\"),\n",
    "    (\"add\", \"add\"),\n",
    "    (\"dec\", \"dec\"),\n",
    "    (\"div\", \"div\"),\n",
    "    (\"eq\", \"eq\"),\n",
    "    (\"mul\", \"mul\"),\n",
    "    (\"sub\", \"sub\"),\n",
    "    (\"x\", \"x\"),\n",
    "    (\"y\", \"y\"),\n",
    "    (\"z\", \"z\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol, csv_name in data_list:\n",
    "    data = load_images(f'./handwritten-digits-and-operators/CompleteImages/All data (Compressed)/{symbol}')\n",
    "    for i in range(len(data)):\n",
    "        data[i] = np.append(data[i], [str(data_list.index((symbol, csv_name)))])\n",
    "    df = pd.DataFrame(data, index=None)\n",
    "    df.to_csv(f\"./processed_data/{csv_name}\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./processed_data\"\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for file in listdir(path):\n",
    "    df_list.append(pd.read_csv(join(path, file)))\n",
    "\n",
    "complete_df = pd.concat(df_list, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset size: 333895\n",
      "Training set size: 200337 (60.00%)\n",
      "Validation set size: 66779 (20.00%)\n",
      "Test set size: 66779 (20.00%)\n"
     ]
    }
   ],
   "source": [
    "labels = complete_df.iloc[:, -1]\n",
    "\n",
    "# First, split off the test set (20% of the data)\n",
    "train_val, test = train_test_split(complete_df, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Extract labels from the train_val set\n",
    "train_val_labels = train_val.iloc[:, -1]\n",
    "\n",
    "# Then split the remaining data into training and validation sets\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42, stratify=train_val_labels)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "# Print the sizes of the resulting datasets\n",
    "print(f\"Full dataset size: {len(complete_df)}\")\n",
    "print(f\"Training set size: {len(train)} ({len(train)/len(complete_df):.2%})\")\n",
    "print(f\"Validation set size: {len(val)} ({len(val)/len(complete_df):.2%})\")\n",
    "print(f\"Test set size: {len(test)} ({len(test)/len(complete_df):.2%})\")\n",
    "\n",
    "# Save the splits to CSV files\n",
    "train.to_csv(\"train_data.csv\", index=False)\n",
    "val.to_csv(\"val_data.csv\", index=False)\n",
    "test.to_csv(\"test_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
