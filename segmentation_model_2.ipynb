{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from cnn_class import CNN\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_segment_image(image_path, target_size=200, min_ratio=0.01, max_ratio=0.5, padding=10):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.bitwise_not(image)  # Invert the image\n",
    "    \n",
    "    # Pad image to enable edge contour search\n",
    "    padding = 1\n",
    "    image = cv2.copyMakeBorder(image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "    \n",
    "    # Resize to target size while maintaining aspect ratio\n",
    "    image = cv2.resize(image, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Convert to grayscale and apply adaptive thresholding\n",
    "    binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Find contours and get bounding boxes\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    \n",
    "    # Filter bounding boxes\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    bounding_boxes = [box for box in bounding_boxes if \n",
    "                      min_ratio * image_area < box[2] * box[3] < max_ratio * image_area]\n",
    "\n",
    "    return image, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_resize_element(element, target_size=(64, 64)): # pad element to square\n",
    "    h, w = element.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = (size - h) // 2\n",
    "    b = size - h - t\n",
    "    l = (size - w) // 2\n",
    "    r = size - w - l\n",
    "    padded = cv2.copyMakeBorder(element, t, b, l, r, cv2.BORDER_CONSTANT, value=0)\n",
    "    resized = cv2.resize(padded, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_element(image, bbox, target_size=(64, 64)):\n",
    "    x, y, w, h = bbox\n",
    "    element = image[y:y+h, x:x+w]\n",
    "    # Pad and resize the element\n",
    "    element = pad_and_resize_element(element, target_size)\n",
    "    # Reshape to (1, 64, 64) to match the expected input shape\n",
    "    element = element.reshape((1, 64, 64)).astype(np.float32)\n",
    "    element /= 255.0\n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    element_tensor = torch.from_numpy(element).float().unsqueeze(0)\n",
    "    \n",
    "    #visualize_preprocessed_element(element_tensor=element_tensor)\n",
    "\n",
    "    return element_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_elements(image, bounding_boxes, model):\n",
    "    results = []\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    \n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        element_tensor = preprocess_element(image, bbox).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(element_tensor)\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            predicted_class = probabilities.argmax(1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "            \n",
    "        results.append((predicted_class, confidence))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = CNN(num_classes=19)  # Adjust num_classes if needed\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_preprocessed_image(image, bounding_boxes):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for (x, y, w, h) in bounding_boxes:\n",
    "        rect = plt.Rectangle((x, y), w, h, fill=False, edgecolor='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "    \n",
    "    plt.title('Preprocessed Image with Bounding Boxes')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'normalized_model.pth'\n",
    "\n",
    "image_path = \"./better_dataset/0/0CdBlhLw.png\"\n",
    "\n",
    "processed_image, bounding_boxes = process_and_segment_image(image_path)\n",
    "\n",
    "model = load_model(model_path)\n",
    "\n",
    "predictions = predict_elements(processed_image, bounding_boxes, model)\n",
    "\n",
    "print(f\"Number of detected elements: {len(bounding_boxes)}\")\n",
    "for i, ((box), (pred, conf)) in enumerate(zip(bounding_boxes, predictions)):\n",
    "    print(f\"Element {i+1}: {box}, Prediction: {pred}, Confidence: {conf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected elements: 1\n",
      "Prediction: 0, Actual: 0\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: 0\n",
      "Prediction: 0, Actual: 0\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: 0, Actual: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: 0, Actual: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: 1, Actual: 1\n",
      "Number of detected elements: 1\n",
      "Prediction: 1, Actual: 1\n",
      "Number of detected elements: 1\n",
      "Prediction: 1, Actual: 1\n",
      "Number of detected elements: 1\n",
      "Prediction: 1, Actual: 1\n",
      "Number of detected elements: 1\n",
      "Prediction: 1, Actual: 1\n",
      "Number of detected elements: 1\n",
      "Prediction: 2, Actual: 2\n",
      "Number of detected elements: 1\n",
      "Prediction: 2, Actual: 2\n",
      "Number of detected elements: 1\n",
      "Prediction: 2, Actual: 2\n",
      "Number of detected elements: 1\n",
      "Prediction: 2, Actual: 2\n",
      "Number of detected elements: 1\n",
      "Prediction: 2, Actual: 2\n",
      "Number of detected elements: 1\n",
      "Prediction: 3, Actual: 3\n",
      "Number of detected elements: 1\n",
      "Prediction: 3, Actual: 3\n",
      "Number of detected elements: 1\n",
      "Prediction: 3, Actual: 3\n",
      "Number of detected elements: 1\n",
      "Prediction: 3, Actual: 3\n",
      "Number of detected elements: 1\n",
      "Prediction: 3, Actual: 3\n",
      "Number of detected elements: 1\n",
      "Prediction: 4, Actual: 4\n",
      "Number of detected elements: 1\n",
      "Prediction: 4, Actual: 4\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: 4\n",
      "Prediction: 4, Actual: 4\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: 4, Actual: 4\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: 5\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: 6\n",
      "Prediction: 6, Actual: 6\n",
      "Number of detected elements: 1\n",
      "Prediction: 6, Actual: 6\n",
      "Number of detected elements: 1\n",
      "Prediction: 6, Actual: 6\n",
      "Number of detected elements: 1\n",
      "Prediction: 6, Actual: 6\n",
      "Number of detected elements: 1\n",
      "Prediction: 6, Actual: 6\n",
      "Number of detected elements: 1\n",
      "Prediction: 7, Actual: 7\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: 7\n",
      "Prediction: 7, Actual: 7\n",
      "Number of detected elements: 1\n",
      "Prediction: 7, Actual: 7\n",
      "Number of detected elements: 1\n",
      "Prediction: 7, Actual: 7\n",
      "Number of detected elements: 1\n",
      "Prediction: 7, Actual: 7\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 1\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: add, Actual: add\n",
      "Number of detected elements: 1\n",
      "Prediction: add, Actual: add\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: add\n",
      "Prediction: add, Actual: add\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: div, Actual: dec\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: dec\n",
      "Number of detected elements: 1\n",
      "Prediction: 8, Actual: dec\n",
      "Number of detected elements: 1\n",
      "Prediction: 5, Actual: dec\n",
      "Number of detected elements: 2\n",
      "Prediction: div, Actual: div\n",
      "Prediction: div, Actual: div\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: div\n",
      "Prediction: 3, Actual: div\n",
      "Number of detected elements: 3\n",
      "Prediction: div, Actual: div\n",
      "Prediction: sub, Actual: div\n",
      "Prediction: div, Actual: div\n",
      "Number of detected elements: 3\n",
      "Prediction: 5, Actual: div\n",
      "Prediction: sub, Actual: div\n",
      "Prediction: sub, Actual: div\n",
      "Number of detected elements: 3\n",
      "Prediction: 8, Actual: div\n",
      "Prediction: sub, Actual: div\n",
      "Prediction: mul, Actual: div\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: eq\n",
      "Prediction: sub, Actual: eq\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: eq\n",
      "Prediction: sub, Actual: eq\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: eq\n",
      "Prediction: sub, Actual: eq\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: eq\n",
      "Prediction: sub, Actual: eq\n",
      "Number of detected elements: 2\n",
      "Prediction: sub, Actual: eq\n",
      "Prediction: sub, Actual: eq\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: mul\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: mul\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: mul\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: mul\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: mul\n",
      "Number of detected elements: 1\n",
      "Prediction: sub, Actual: sub\n",
      "Number of detected elements: 1\n",
      "Prediction: sub, Actual: sub\n",
      "Number of detected elements: 1\n",
      "Prediction: sub, Actual: sub\n",
      "Number of detected elements: 1\n",
      "Prediction: sub, Actual: sub\n",
      "Number of detected elements: 1\n",
      "Prediction: sub, Actual: sub\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: x\n",
      "Number of detected elements: 1\n",
      "Prediction: div, Actual: x\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: x\n",
      "Number of detected elements: 1\n",
      "Prediction: mul, Actual: x\n",
      "Number of detected elements: 1\n",
      "Prediction: y, Actual: y\n",
      "Number of detected elements: 2\n",
      "Prediction: mul, Actual: y\n",
      "Prediction: mul, Actual: y\n",
      "Number of detected elements: 1\n",
      "Prediction: y, Actual: y\n",
      "Number of detected elements: 1\n",
      "Prediction: y, Actual: y\n",
      "Number of detected elements: 1\n",
      "Prediction: y, Actual: y\n",
      "Number of detected elements: 1\n",
      "Prediction: z, Actual: z\n",
      "Number of detected elements: 1\n",
      "Prediction: z, Actual: z\n",
      "Number of detected elements: 0\n",
      "Number of detected elements: 1\n",
      "Prediction: z, Actual: z\n",
      "Number of detected elements: 1\n",
      "Prediction: z, Actual: z\n",
      "\n",
      "Overall Accuracy: 68.22%\n",
      "Correct Predictions: 73\n",
      "Total Predictions: 107\n"
     ]
    }
   ],
   "source": [
    "symbols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'add', 'dec', 'div', 'eq', 'mul', 'sub', 'x', 'y', 'z']\n",
    "model_path = \"normalized_model.pth\"  # Adjust this to your model's path\n",
    "model = load_model(model_path)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for symbol_index, symbol in enumerate(symbols):\n",
    "    files = os.listdir(f\"./better_dataset/{symbol}\")\n",
    "    sample_files = random.sample(files, min(5, len(files)))\n",
    "    for file_name in sample_files:\n",
    "        image_path = f\"./better_dataset/{symbol}/{file_name}\"\n",
    "        # Process and segment the image\n",
    "        processed_image, bounding_boxes = process_and_segment_image(image_path)\n",
    "        predictions = predict_elements(processed_image, bounding_boxes, model)\n",
    "\n",
    "        print(f\"Number of detected elements: {len(bounding_boxes)}\")\n",
    "        for i, ((box), (pred, conf)) in enumerate(zip(bounding_boxes, predictions)):\n",
    "            print(f\"Prediction: {symbols[pred]}, Actual: {symbol}\")\n",
    "            \n",
    "            # Update accuracy counters\n",
    "            total_predictions += 1\n",
    "            if pred == symbol_index:\n",
    "                correct_predictions += 1\n",
    "\n",
    "# Calculate and print overall accuracy\n",
    "if total_predictions > 0:\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Correct Predictions: {correct_predictions}\")\n",
    "    print(f\"Total Predictions: {total_predictions}\")\n",
    "else:\n",
    "    print(\"No predictions were made.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on handwritten multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"normalized_model.pth\"  # Adjust this to your model's path\n",
    "model = load_model(model_path)\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(f\"./handwritten-series\"):\n",
    "    image_path = f\"./handwritten-series/{file_name}\"\n",
    "    # Process and segment the image\n",
    "    processed_image, bounding_boxes = process_and_segment_image(image_path)\n",
    "\n",
    "    predictions = predict_elements(processed_image, bounding_boxes, model)\n",
    "\n",
    "    print(f\"Number of detected elements: {len(bounding_boxes)}\")\n",
    "    for i, ((box), (pred, conf)) in enumerate(zip(bounding_boxes, predictions)):\n",
    "        #print(f\"Element {i+1}: {box}, Prediction: {pred}, Confidence: {conf:.2f}, Actual: {symbol}\")\n",
    "        print(f\"Prediction: {pred}\")\n",
    "    #display_image_and_results(processed_image, bounding_boxes, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
