{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.features = self.data.iloc[:, :-1].values.astype(np.float32)\n",
    "        self.labels = self.data.iloc[:, -1].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.features[idx].reshape(28, 28)  # Assuming 28x28 images\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_data = ExpDataset('train_data.csv')\n",
    "val_data = ExpDataset('val_data.csv')\n",
    "test_data = ExpDataset('test_data.csv')\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 16  # Digits 0-9, operators +, -, *, /, and brackets (, )\n",
    "model = CNN(num_classes)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/100, Batch 0/1044, Loss: 0.2511\n",
      "Epoch 1/100, Batch 100/1044, Loss: 0.2426\n",
      "Epoch 1/100, Batch 200/1044, Loss: 0.1674\n",
      "Epoch 1/100, Batch 300/1044, Loss: 0.0428\n",
      "Epoch 1/100, Batch 400/1044, Loss: 0.0805\n",
      "Epoch 1/100, Batch 500/1044, Loss: 0.0507\n",
      "Epoch 1/100, Batch 600/1044, Loss: 0.1203\n",
      "Epoch 1/100, Batch 700/1044, Loss: 0.0667\n",
      "Epoch 1/100, Batch 800/1044, Loss: 0.0251\n",
      "Epoch 1/100, Batch 900/1044, Loss: 0.2638\n",
      "Epoch 1/100, Batch 1000/1044, Loss: 0.0663\n",
      "Epoch 1/100:\n",
      "Train Loss: 0.0296, Train Accuracy: 0.9718\n",
      "Val Loss: 0.0713, Val Accuracy: 0.9771\n",
      "Learning Rate: 0.000010\n",
      "---\n",
      "Epoch 2/100, Batch 0/1044, Loss: 0.0827\n",
      "Epoch 2/100, Batch 100/1044, Loss: 0.0590\n",
      "Epoch 2/100, Batch 200/1044, Loss: 0.1073\n",
      "Epoch 2/100, Batch 300/1044, Loss: 0.0965\n",
      "Epoch 2/100, Batch 400/1044, Loss: 0.0481\n",
      "Epoch 2/100, Batch 500/1044, Loss: 0.0792\n",
      "Epoch 2/100, Batch 600/1044, Loss: 0.1936\n",
      "Epoch 2/100, Batch 700/1044, Loss: 0.0929\n",
      "Epoch 2/100, Batch 800/1044, Loss: 0.0392\n",
      "Epoch 2/100, Batch 900/1044, Loss: 0.4009\n",
      "Epoch 2/100, Batch 1000/1044, Loss: 0.0588\n",
      "Epoch 2/100:\n",
      "Train Loss: 0.0296, Train Accuracy: 0.9709\n",
      "Val Loss: 0.0712, Val Accuracy: 0.9773\n",
      "Learning Rate: 0.000010\n",
      "---\n",
      "Epoch 3/100, Batch 0/1044, Loss: 0.1738\n",
      "Epoch 3/100, Batch 100/1044, Loss: 0.0785\n",
      "Epoch 3/100, Batch 200/1044, Loss: 0.1040\n",
      "Epoch 3/100, Batch 300/1044, Loss: 0.0515\n",
      "Epoch 3/100, Batch 400/1044, Loss: 0.0694\n",
      "Epoch 3/100, Batch 500/1044, Loss: 0.1044\n",
      "Epoch 3/100, Batch 600/1044, Loss: 0.1913\n",
      "Epoch 3/100, Batch 700/1044, Loss: 0.0490\n",
      "Epoch 3/100, Batch 800/1044, Loss: 0.0496\n",
      "Epoch 3/100, Batch 900/1044, Loss: 0.3838\n",
      "Epoch 3/100, Batch 1000/1044, Loss: 0.0408\n",
      "Epoch 3/100:\n",
      "Train Loss: 0.0293, Train Accuracy: 0.9716\n",
      "Val Loss: 0.0714, Val Accuracy: 0.9772\n",
      "Learning Rate: 0.000010\n",
      "---\n",
      "Epoch 4/100, Batch 0/1044, Loss: 0.1202\n",
      "Epoch 4/100, Batch 100/1044, Loss: 0.1296\n",
      "Epoch 4/100, Batch 200/1044, Loss: 0.1116\n",
      "Epoch 4/100, Batch 300/1044, Loss: 0.0433\n",
      "Epoch 4/100, Batch 400/1044, Loss: 0.0864\n",
      "Epoch 4/100, Batch 500/1044, Loss: 0.1247\n",
      "Epoch 4/100, Batch 600/1044, Loss: 0.1988\n",
      "Epoch 4/100, Batch 700/1044, Loss: 0.1344\n",
      "Epoch 4/100, Batch 800/1044, Loss: 0.0502\n",
      "Epoch 4/100, Batch 900/1044, Loss: 0.3663\n",
      "Epoch 4/100, Batch 1000/1044, Loss: 0.0321\n",
      "Epoch 4/100:\n",
      "Train Loss: 0.0286, Train Accuracy: 0.9716\n",
      "Val Loss: 0.0714, Val Accuracy: 0.9773\n",
      "Learning Rate: 0.000010\n",
      "Early stopping triggered after 4 epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patience = 3  # Number of epochs to wait for improvement\n",
    "min_delta = 0.001  # Minimum change in validation loss to qualify as an improvement\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model = model.to(device)\n",
    "num_epochs = 100\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        train_total += target.size(0)\n",
    "        train_correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(test_loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_loss += criterion(output, target).item()\n",
    "            _, predicted = output.max(1)\n",
    "            val_total += target.size(0)\n",
    "            val_correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}')\n",
    "    print(f'Learning Rate: {scheduler.get_last_lr()[0]:.6f}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss - min_delta:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model_cnn2.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "    \n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "        break\n",
    "    \n",
    "    print('---')\n",
    "\n",
    "# Load the best model for testing\n",
    "model.load_state_dict(torch.load('best_model_cnn2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0003, Test Accuracy: 0.9727\n",
      "\n",
      "Sample Predictions:\n",
      "Sample 1:\n",
      "Ground Truth: (\n",
      "Prediction: (\n",
      "Correct: True\n",
      "---\n",
      "Sample 2:\n",
      "Ground Truth: 4\n",
      "Prediction: 4\n",
      "Correct: True\n",
      "---\n",
      "Sample 3:\n",
      "Ground Truth: *\n",
      "Prediction: *\n",
      "Correct: True\n",
      "---\n",
      "Sample 4:\n",
      "Ground Truth: 0\n",
      "Prediction: 0\n",
      "Correct: True\n",
      "---\n",
      "Sample 5:\n",
      "Ground Truth: 9\n",
      "Prediction: 9\n",
      "Correct: True\n",
      "---\n",
      "Sample 6:\n",
      "Ground Truth: *\n",
      "Prediction: *\n",
      "Correct: True\n",
      "---\n",
      "Sample 7:\n",
      "Ground Truth: 5\n",
      "Prediction: 5\n",
      "Correct: True\n",
      "---\n",
      "Sample 8:\n",
      "Ground Truth: -\n",
      "Prediction: -\n",
      "Correct: True\n",
      "---\n",
      "Sample 9:\n",
      "Ground Truth: 3\n",
      "Prediction: 5\n",
      "Correct: False\n",
      "---\n",
      "Sample 10:\n",
      "Ground Truth: -\n",
      "Prediction: -\n",
      "Correct: True\n",
      "---\n",
      "Sample 11:\n",
      "Ground Truth: 1\n",
      "Prediction: 1\n",
      "Correct: True\n",
      "---\n",
      "Sample 12:\n",
      "Ground Truth: 0\n",
      "Prediction: 0\n",
      "Correct: True\n",
      "---\n",
      "Sample 13:\n",
      "Ground Truth: /\n",
      "Prediction: /\n",
      "Correct: True\n",
      "---\n",
      "Sample 14:\n",
      "Ground Truth: +\n",
      "Prediction: +\n",
      "Correct: True\n",
      "---\n",
      "Sample 15:\n",
      "Ground Truth: 6\n",
      "Prediction: 6\n",
      "Correct: True\n",
      "---\n",
      "Sample 16:\n",
      "Ground Truth: 8\n",
      "Prediction: 8\n",
      "Correct: True\n",
      "---\n",
      "Sample 17:\n",
      "Ground Truth: +\n",
      "Prediction: +\n",
      "Correct: True\n",
      "---\n",
      "Sample 18:\n",
      "Ground Truth: -\n",
      "Prediction: -\n",
      "Correct: True\n",
      "---\n",
      "Sample 19:\n",
      "Ground Truth: 6\n",
      "Prediction: 6\n",
      "Correct: True\n",
      "---\n",
      "Sample 20:\n",
      "Ground Truth: 3\n",
      "Prediction: 3\n",
      "Correct: True\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "model = CNN(num_classes=16)  # Adjust num_classes if needed\n",
    "model.load_state_dict(torch.load(\"best_model_cnn2.pth\"))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "# Define class mapping\n",
    "class_mapping = {\n",
    "    0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "    10: '+', 11: '-', 12: '*', 13: '/', 14: '(', 15: ')'\n",
    "}\n",
    "\n",
    "# List to store sample predictions\n",
    "sample_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        _, predicted = output.max(1)\n",
    "        test_total += target.size(0)\n",
    "        test_correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        # Store some sample predictions\n",
    "        for true, pred in zip(target[:5], predicted[:5]):  # Store up to 5 samples per batch\n",
    "            sample_predictions.append((true.item(), pred.item()))\n",
    "        \n",
    "        if len(sample_predictions) >= 20:  # Stop after collecting 20 samples\n",
    "            break\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for i, (true, pred) in enumerate(sample_predictions[:20], 1):\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Ground Truth: {class_mapping[true]}\")\n",
    "    print(f\"Prediction: {class_mapping[pred]}\")\n",
    "    print(f\"Correct: {true == pred}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0445, Test Accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item()\n",
    "        _, predicted = output.max(1)\n",
    "        test_total += target.size(0)\n",
    "        test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
