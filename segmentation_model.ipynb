{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cnn_class import CNN\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_square(image, padding=5):\n",
    "    # Add initial padding\n",
    "    image_padded = cv2.copyMakeBorder(image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[255,255,255])\n",
    "    \n",
    "    h, w = image_padded.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = (size - h) // 2\n",
    "    b = size - h - t\n",
    "    l = (size - w) // 2\n",
    "    r = size - w - l\n",
    "    return cv2.copyMakeBorder(image_padded, t, b, l, r, cv2.BORDER_CONSTANT, value=[255,255,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_segment_image(image_path, target_size=200, min_ratio=0.01, max_ratio=0.5, padding=10):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Pad image to square with initial padding\n",
    "    image = pad_to_square(image, padding)\n",
    "    \n",
    "    # Resize to target size while maintaining aspect ratio\n",
    "    image = cv2.resize(image, (target_size, target_size), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Convert to grayscale and apply adaptive thresholding\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Find contours and get bounding boxes\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "    \n",
    "    # Filter bounding boxes\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    bounding_boxes = [box for box in bounding_boxes if \n",
    "                      min_ratio * image_area < box[2] * box[3] < max_ratio * image_area]\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    for (x, y, w, h) in bounding_boxes:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    return image, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_resize_element(element, target_size=(28, 28)):\n",
    "    h, w = element.shape[:2]\n",
    "    size = max(h, w)\n",
    "    t = (size - h) // 2\n",
    "    b = size - h - t\n",
    "    l = (size - w) // 2\n",
    "    r = size - w - l\n",
    "    padded = cv2.copyMakeBorder(element, t, b, l, r, cv2.BORDER_CONSTANT, value=255)\n",
    "    resized = cv2.resize(padded, target_size, interpolation=cv2.INTER_AREA)\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_element(image, bbox, target_size=(28, 28)):\n",
    "    x, y, w, h = bbox\n",
    "    element = image[y:y+h, x:x+w]\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    element = cv2.cvtColor(element, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pad and resize the element\n",
    "    element = pad_and_resize_element(element, target_size)\n",
    "    \n",
    "    # Invert the image (255 - pixel_value)\n",
    "    element = 255 - element\n",
    "    \n",
    "    # Reshape to (1, 28, 28) to match the expected input shape\n",
    "    element = element.reshape((1, 28, 28)).astype(np.float32)\n",
    "    \n",
    "    # Normalize the image (divide by 255 to get values between 0 and 1)\n",
    "    #element = element / 255.0\n",
    "    \n",
    "    # Convert to PyTorch tensor and add batch dimension\n",
    "    element_tensor = torch.from_numpy(element).float().unsqueeze(0)\n",
    "    \n",
    "    return element_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_elements(image, bounding_boxes, model):\n",
    "    results = []\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    \n",
    "    for i, bbox in enumerate(bounding_boxes):\n",
    "        element_tensor = preprocess_element(image, bbox).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(element_tensor)\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            predicted_class = probabilities.argmax(1).item()\n",
    "            confidence = probabilities[0][predicted_class].item()\n",
    "            \n",
    "        results.append((predicted_class, confidence))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = CNN(num_classes=16)  # Adjust num_classes if needed\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image_and_results(image, bounding_boxes, predictions):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Segmented Image with Predictions\")\n",
    "    image_tk = ImageTk.PhotoImage(Image.fromarray(image_rgb))\n",
    "    label = tk.Label(root, image=image_tk)\n",
    "    label.pack()\n",
    "\n",
    "    # Display predictions\n",
    "    for (x, y, w, h), (pred, conf) in zip(bounding_boxes, predictions):\n",
    "        text = f\"Pred: {pred} ({conf:.2f})\"\n",
    "        cv2.putText(image_rgb, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Update the image with predictions\n",
    "    image_tk_updated = ImageTk.PhotoImage(Image.fromarray(image_rgb))\n",
    "    label.config(image=image_tk_updated)\n",
    "    label.image = image_tk_updated\n",
    "\n",
    "    close_button = tk.Button(root, text=\"Close\", command=root.quit)\n",
    "    close_button.pack()\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected elements: 3\n",
      "Element 1: (84, 138, 34, 46), Prediction: 0, Confidence: 0.88\n",
      "Element 2: (77, 84, 46, 34), Prediction: 0, Confidence: 0.64\n",
      "Element 3: (82, 16, 36, 46), Prediction: 0, Confidence: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "image_path = \"./handwritten-digits-and-operators/CompleteImages/All data (Compressed)/6/6_1_0.png\"\n",
    "\n",
    "#image_path = \"debug_element_60_25.png\"\n",
    "#image_path = \"898.jpg\"\n",
    "image_path = \"handwritten-series/234.jpg\"\n",
    "image_path = \"handwritten-series/898.jpg\"\n",
    "image_path = \"combined_test_image.png\"\n",
    "\n",
    "\n",
    "model_path = \"best_model_cnn.pth\"  # Adjust this to your model's path\n",
    "\n",
    "# Process and segment the image\n",
    "processed_image, bounding_boxes = process_and_segment_image(image_path)\n",
    "\n",
    "model = load_model(model_path)\n",
    "model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "predictions = predict_elements(processed_image, bounding_boxes, model)\n",
    "\n",
    "print(f\"Number of detected elements: {len(bounding_boxes)}\")\n",
    "for i, ((box), (pred, conf)) in enumerate(zip(bounding_boxes, predictions)):\n",
    "    print(f\"Element {i+1}: {box}, Prediction: {pred}, Confidence: {conf:.2f}\")\n",
    "\n",
    "display_image_and_results(processed_image, bounding_boxes, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 0\n",
      "Prediction: 0, Actual: 0\n",
      "Prediction: 9, Actual: 0\n",
      "Number of detected elements: 2\n",
      "Prediction: 9, Actual: 1\n",
      "Prediction: 9, Actual: 1\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 2\n",
      "Prediction: 8, Actual: 2\n",
      "Prediction: 9, Actual: 2\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 3\n",
      "Prediction: 8, Actual: 3\n",
      "Prediction: 9, Actual: 3\n",
      "Number of detected elements: 3\n",
      "Prediction: 4, Actual: 4\n",
      "Prediction: 8, Actual: 4\n",
      "Prediction: 9, Actual: 4\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 5\n",
      "Prediction: 5, Actual: 5\n",
      "Prediction: 9, Actual: 5\n",
      "Number of detected elements: 3\n",
      "Prediction: 6, Actual: 6\n",
      "Prediction: 5, Actual: 6\n",
      "Prediction: 5, Actual: 6\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 7\n",
      "Prediction: 7, Actual: 7\n",
      "Prediction: 9, Actual: 7\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 8\n",
      "Prediction: 9, Actual: 8\n",
      "Prediction: 8, Actual: 8\n",
      "Number of detected elements: 3\n",
      "Prediction: 9, Actual: 9\n",
      "Prediction: 9, Actual: 9\n",
      "Prediction: 9, Actual: 9\n",
      "Number of detected elements: 3\n",
      "Prediction: 8, Actual: +\n",
      "Prediction: 10, Actual: +\n",
      "Prediction: 8, Actual: +\n",
      "Number of detected elements: 3\n",
      "Prediction: 10, Actual: -\n",
      "Prediction: 10, Actual: -\n",
      "Prediction: 10, Actual: -\n",
      "Number of detected elements: 3\n",
      "Prediction: 1, Actual: %\n",
      "Prediction: 2, Actual: %\n",
      "Prediction: 2, Actual: %\n",
      "Number of detected elements: 3\n",
      "Prediction: 8, Actual: *\n",
      "Prediction: 8, Actual: *\n",
      "Prediction: 8, Actual: *\n",
      "Number of detected elements: 3\n",
      "Prediction: 11, Actual: [\n",
      "Prediction: 12, Actual: [\n",
      "Prediction: 11, Actual: [\n",
      "Number of detected elements: 3\n",
      "Prediction: 6, Actual: ]\n",
      "Prediction: 12, Actual: ]\n",
      "Prediction: 1, Actual: ]\n"
     ]
    }
   ],
   "source": [
    "symbols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '+', '-', '%', '*', '[', ']']\n",
    "for symbol in symbols:\n",
    "    image_path = f\"./combined_img/{symbol}.png\"\n",
    "    model_path = \"best_model_cnn.pth\"  # Adjust this to your model's path\n",
    "\n",
    "    # Process and segment the image\n",
    "    processed_image, bounding_boxes = process_and_segment_image(image_path)\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "\n",
    "    predictions = predict_elements(processed_image, bounding_boxes, model)\n",
    "\n",
    "    print(f\"Number of detected elements: {len(bounding_boxes)}\")\n",
    "    for i, ((box), (pred, conf)) in enumerate(zip(bounding_boxes, predictions)):\n",
    "        #print(f\"Element {i+1}: {box}, Prediction: {pred}, Confidence: {conf:.2f}, Actual: {symbol}\")\n",
    "        print(f\"Prediction: {pred}, Actual: {symbol}\")\n",
    "    display_image_and_results(processed_image, bounding_boxes, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
